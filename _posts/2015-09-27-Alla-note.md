---
layout: post
title: Alla's note.
category: draft
use_math: true
---
## Variables##
> **TODO**  
> Think about the mid-edge and edge-end point (for deal with both corners and sides.)

$$e_i = P_{i1} \times (1-t) + P_{i2}\times t, 0<=t <=1$$

## Features##
> **TODO**  
> write more detail about each feature

### Context-free feature
Encode neighbourhoods in terms of distance to subsequent left/right corners and the relative orientation of these corners.  

### Context feature
Contain current values of $e_i$ and X ``rings'' of $e$ values, i.e.  ($$ ... e_{i-1}, e_i, e_{i+1}, ... $$)


## Optimization##
$$ E_{curve} =  W_{1st(e_i)}\| e_i - (e_{i-1}+e_{i+1})/2\| _0  \\
     + W_{2nd(e_i)} \| e_i - (e_{i-1} + e_{i+1})/2  - (e_{i-1} - (e_{i-2} + e_{i})/2 + e_{i+1} - (e_{i} + e_{i+2})/2  )/2  \|_0$$ 

There are linearized terms for 

- minimizing curvature
- keeping curvature constant
 
$L_0$ aims to indicate that we want to allow some but not many places where this error is high..

The algorithm would be:

1. compute context-free weights (generate these using CNN based on training..)  

2. Minimize our quadratic function (with linear inequalities):  

$$ E_{curve2} =  W_{1st(e_i)}\| e_i - (e_{i-1}+e_{i+1})/2\| _2  \\
     + W_{2nd(e_i)} \| e_i - (e_{i-1} + e_{i+1})/2  - (e_{i-1} - (e_{i-2} + e_{i})/2 + e_{i+1} - (e_{i} + e_{i+2})/2  )/2  \|_2 $$                  

3. Update weights based on both feature vectors and $e_k$ values in an immediate neighborhood (rere rings of end-points) - i.e. compute context
based weights  (again train the network to give contextual weights)  

4. repeat 2, 3 till weights/values no longer change.




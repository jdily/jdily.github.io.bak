<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

 <title>Smooth Voxel Modeling</title>
 <link href="http://jdily.github.io/atom.xml" rel="self"/>
 <link href="http://jdily.github.io/"/>
 <updated>2015-10-05T13:40:03-07:00</updated>
 <id>http://jdily.github.io</id>
 <author>
   <name>I-Chao Shen</name>
   <email>jdilyshen@gmail.com</email>
 </author>

 
 <entry>
   <title>Optimization draft</title>
   <link href="http://jdily.github.io/progress/2015/10/02/Optimization-draft/"/>
   <updated>2015-10-02T00:00:00-07:00</updated>
   <id>http://jdily.github.io/progress/2015/10/02/Optimization-draft</id>
   <content type="html">&lt;h2 id=&quot;optimization-with-anisotropic-weights&quot;&gt;Optimization with anisotropic weights&lt;/h2&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt; E_{curve} = E_{min} + E_{const}&lt;/script&gt;

&lt;h3 id=&quot;term1--minimizing-curvature---emin--&quot;&gt;Term1 : minimizing curvature  &lt;script type=&quot;math/tex&quot;&gt; (E_{min})  &lt;/script&gt;&lt;/h3&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;  \sum_{e_i} W_{1st(e_i)}\| e_i - (e_{i-1}+e_{i+1})/2\| _2^2 &lt;/script&gt;

&lt;h3 id=&quot;term2--keeping-curvature-constant---econst--&quot;&gt;Term2 : keeping curvature constant  &lt;script type=&quot;math/tex&quot;&gt; (E_{const})  &lt;/script&gt;&lt;/h3&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;  \sum_{e_i } W_{2nd(e_i)} \| e_i - (e_{i-1} + e_{i+1})/2  - (e_{i-1} - (e_{i-2} + e_{i})/2 + e_{i+1} - (e_{i} + e_{i+2})/2  )/2  \|_2^2 &lt;/script&gt;

&lt;h3 id=&quot;note&quot;&gt;Note&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Now I use square distance of 2-norm.&lt;/li&gt;
  &lt;li&gt;The only constraints I have now for each $e_i$ is $ 0 \leq e_i \leq 1$.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;experiment&quot;&gt;Experiment&lt;/h3&gt;

&lt;p&gt;To try out the optimization, I optimize different shapes and different weights combinations.&lt;/p&gt;

&lt;h4 id=&quot;isotropic-weights&quot;&gt;isotropic weights&lt;/h4&gt;

&lt;p&gt;In these examples, I use both weighting as 0.5. Please see the following results:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.cs.ubc.ca/~ichaos/research/nbview/solver%20viz-circle109.html&quot;&gt;https://www.cs.ubc.ca/~ichaos/research/nbview/solver%20viz-circle109.html&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.cs.ubc.ca/~ichaos/research/nbview/solver%20viz-rect1.html&quot;&gt;https://www.cs.ubc.ca/~ichaos/research/nbview/solver%20viz-rect1.html&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.cs.ubc.ca/~ichaos/research/nbview/solver%20viz-heart298.html&quot;&gt;https://www.cs.ubc.ca/~ichaos/research/nbview/solver%20viz-heart298.html&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.cs.ubc.ca/~ichaos/research/nbview/solver%20viz-triangle36.html&quot;&gt;https://www.cs.ubc.ca/~ichaos/research/nbview/solver%20viz-triangle36.html&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.cs.ubc.ca/~ichaos/research/nbview/solver%20viz-phone.html&quot;&gt;https://www.cs.ubc.ca/~ichaos/research/nbview/solver%20viz-phone.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;anisotropic-weights&quot;&gt;anisotropic weights&lt;/h4&gt;

&lt;p&gt;The thing is that I tried to add anisotropic weights into the optimization, but I didn’t get reasonable results when I manually set the weights.
Most of the time, the result are just very close to the isotropic weights results.
So I did a test that randomly generate the weights for every $e_i$, and the results still looks very close, and the optimized energy from the solver are close.&lt;/p&gt;

&lt;p&gt;I am trying to find out what is the problem right now… &lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Alla's note.</title>
   <link href="http://jdily.github.io/draft/2015/09/27/Alla-note/"/>
   <updated>2015-09-27T00:00:00-07:00</updated>
   <id>http://jdily.github.io/draft/2015/09/27/Alla-note</id>
   <content type="html">&lt;h2 id=&quot;variables&quot;&gt;Variables&lt;/h2&gt;
&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;TODO&lt;/strong&gt;&lt;br /&gt;
Think about the mid-edge and edge-end point (for deal with both corners and sides.)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
e_i = P_{i1} \times (1-t) + P_{i2}\times t, 0&lt;=t &lt;=1 %]]&gt;&lt;/script&gt;

&lt;h2 id=&quot;features&quot;&gt;Features&lt;/h2&gt;
&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;TODO&lt;/strong&gt;&lt;br /&gt;
write more detail about each feature&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;context-free-feature&quot;&gt;Context-free feature&lt;/h3&gt;
&lt;p&gt;Encode neighbourhoods in terms of distance to subsequent left/right corners and the relative orientation of these corners.  &lt;/p&gt;

&lt;h3 id=&quot;context-feature&quot;&gt;Context feature&lt;/h3&gt;
&lt;p&gt;Contain current values of $e_i$ and X ``rings’’ of $e$ values, i.e.  (&lt;script type=&quot;math/tex&quot;&gt; ... e_{i-1}, e_i, e_{i+1}, ... &lt;/script&gt;)&lt;/p&gt;

&lt;h2 id=&quot;optimization&quot;&gt;Optimization&lt;/h2&gt;
&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt; E_{curve} =  W_{1st(e_i)}\| e_i - (e_{i-1}+e_{i+1})/2\| _0  \\
     + W_{2nd(e_i)} \| e_i - (e_{i-1} + e_{i+1})/2  - (e_{i-1} - (e_{i-2} + e_{i})/2 + e_{i+1} - (e_{i} + e_{i+2})/2  )/2  \|_0&lt;/script&gt; &lt;/p&gt;

&lt;p&gt;There are linearized terms for &lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;minimizing curvature&lt;/li&gt;
  &lt;li&gt;keeping curvature constant&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;$L_0$ aims to indicate that we want to allow some but not many places where this error is high..&lt;/p&gt;

&lt;p&gt;The algorithm would be:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;compute context-free weights (generate these using CNN based on training..)  &lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Minimize our quadratic function (with linear inequalities):  &lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt; E_{curve2} =  W_{1st(e_i)}\| e_i - (e_{i-1}+e_{i+1})/2\| _2  \\
     + W_{2nd(e_i)} \| e_i - (e_{i-1} + e_{i+1})/2  - (e_{i-1} - (e_{i-2} + e_{i})/2 + e_{i+1} - (e_{i} + e_{i+2})/2  )/2  \|_2 &lt;/script&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Update weights based on both feature vectors and $e_k$ values in an immediate neighborhood (rere rings of end-points) - i.e. compute context
based weights  (again train the network to give contextual weights)  &lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;repeat 2, 3 till weights/values no longer change.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

</content>
 </entry>
 
 <entry>
   <title>Sep 23, 2015 Meeting note</title>
   <link href="http://jdily.github.io/meeting/2015/09/23/meeting/"/>
   <updated>2015-09-23T00:00:00-07:00</updated>
   <id>http://jdily.github.io/meeting/2015/09/23/meeting</id>
   <content type="html">&lt;h2 id=&quot;importants&quot;&gt;Importants&lt;/h2&gt;
&lt;p&gt;Next meeting : Sep 29 (Tue), 1:00 pm  &lt;/p&gt;

&lt;h2 id=&quot;notes&quot;&gt;Notes&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Visualization should be changed so that we can see the line clearer.&lt;/li&gt;
  &lt;li&gt;Smoothness issue
    &lt;ul&gt;
      &lt;li&gt;leverage local laplacian, i.e. describe a pixel crossing with two neighbors.&lt;/li&gt;
      &lt;li&gt;find out what we want, i.e. the optimization function.&lt;/li&gt;
      &lt;li&gt;We can 
        &lt;ul&gt;
          &lt;li&gt;use network results as initial value (i.e. using network to do the feature pattern-&amp;gt;crossing value mapping, because it’s hard to formulate as a numerical optimization.)&lt;/li&gt;
          &lt;li&gt;and do a post-optimization for smoothness (this one is easier to do optimization.)  &lt;/li&gt;
          &lt;li&gt;Also, we can try to incorporate this process into the network, as a new layer.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;The current result can be consider as first-order prediction, we can try to make the loss (objective) function complicated and try to predict some other things.&lt;/li&gt;
      &lt;li&gt;For interactive usage, if post-optimization (globally) is needed, we can only do it once a while, but not after every update.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;action-items&quot;&gt;Action Items&lt;/h2&gt;
&lt;ol&gt;
  &lt;li&gt;generate double feature set -&amp;gt; for reflective symmetries&lt;/li&gt;
  &lt;li&gt;Run experiment -&amp;gt; use triangle and rect to reconstruct arrow.&lt;/li&gt;
  &lt;li&gt;drafting the introduction, including notation and target optimization function.&lt;/li&gt;
  &lt;li&gt;experiment with the two step optimization including laplacian&lt;/li&gt;
  &lt;li&gt;integrate caffe model into c++&lt;/li&gt;
  &lt;li&gt;Implement the new representation and compare..&lt;/li&gt;
&lt;/ol&gt;

</content>
 </entry>
 
 <entry>
   <title>Arrow result</title>
   <link href="http://jdily.github.io/progress/2015/09/22/arrow-result/"/>
   <updated>2015-09-22T00:00:00-07:00</updated>
   <id>http://jdily.github.io/progress/2015/09/22/arrow-result</id>
   <content type="html">&lt;p&gt;Hi guys, I put a new result here 
Please see 
&lt;a href=&quot;http://www.cs.ubc.ca/~ichaos/research/nbview/arrow-up.html&quot;&gt;http://www.cs.ubc.ca/~ichaos/research/nbview/arrow-up.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Right now I am training on a bigger dataset.&lt;/p&gt;

&lt;p&gt;ichao&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Learning rate tuning</title>
   <link href="http://jdily.github.io/progress/2015/09/17/learning-rate-tuning/"/>
   <updated>2015-09-17T00:00:00-07:00</updated>
   <id>http://jdily.github.io/progress/2015/09/17/learning-rate-tuning</id>
   <content type="html">&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;learning rate&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;loss&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;loss&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;loss&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0.01&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0.0086047&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0.0098077&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0.0096455 &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0.1&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0.0061281 &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0.0057908&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0.0065994&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0.2&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; 0.0084242&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0.0083152&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0.0074397&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0.5&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0.0423556 &lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0.0422975&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;font color=&quot;red&quot;&gt;0.0124222 &lt;/font&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;There is one strange loss for lr=0.5.. I ran it several times, and sometimes there is one smaller value… &lt;/p&gt;

</content>
 </entry>
 

</feed>
